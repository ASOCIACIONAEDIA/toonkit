# TOONKIT - Ejemplos de Uso / Usage Examples

Este directorio contiene ejemplos completos de como usar TOONKIT en sistemas reales que integran APIs de IA.

## üìÅ Archivos

### 1. `example_complete.py` - Gu√≠a Completa Interactiva
**13 ejemplos detallados mostrando todas las caracter√≠sticas**

```bash
python example_complete.py
```

Incluye:
- Ejemplos 1-10: Caracter√≠sticas b√°sicas de TOONKIT
- Ejemplo 11: Integraci√≥n con OpenAI GPT-4 (ahorros reales de costos)
- Ejemplo 12: Integraci√≥n con Claude API (Anthropic)
- Ejemplo 13: Comparativa de ahorros entre m√∫ltiples LLMs

**Output esperado:**
- Demostraciones bilingual (Espa√±ol/Ingl√©s)
- C√°lculos de reducci√≥n de tama√±o
- Estimaciones de ahorros de costos
- C√≥digo de integraci√≥n listo para usar

---

### 2. `demo_llm_savings.py` - Calculadora de Ahorros
**Calcula ahorros reales en 3 casos de uso diferentes**

```bash
python demo_llm_savings.py
```

Casos analizados:
1. **Sistema de Soporte al Cliente**
   - Contexto: perfiles, historial de conversaci√≥n, tickets
   - Reducci√≥n: ~52%
   - Ahorro anual: $14,227 (con GPT-4 + Claude)
   - ROI: 285% en 4.2 meses

2. **Analytics Pipeline**
   - Contexto: reportes diarios, m√©tricas, eventos
   - Reducci√≥n: ~32%
   - Ahorro anual: $2,607
   - ROI: 52% en 23 meses

3. **Document Processing**
   - Contexto: documentos legales con anotaciones
   - Reducci√≥n: ~2-3%
   - Ahorro anual: $352

---

### 3. `integration_examples.py` - Ejemplos de Integraci√≥n Real
**C√≥digo listo para copiar/pegar en tus proyectos**

```bash
python integration_examples.py
```

Incluye c√≥digo para:

#### OpenAI GPT-4
```python
from toonkit import encode

# Antes (caro):
message = {"role": "user", "content": json.dumps(context)}

# Despu√©s (barato):
message = {"role": "user", "content": encode(context)}
```

#### Anthropic Claude
```python
client = anthropic.Anthropic()
response = client.messages.create(
    model="claude-3-opus-20240229",
    messages=[{
        "role": "user",
        "content": encode(analytics_data)
    }]
)
```

#### Google Gemini
```python
model = genai.GenerativeModel("gemini-pro")
response = model.generate_content(encode(conversation_data))
```

#### Ejemplo Completo con Proyecciones
Simula un CRM enviando contexto de cliente a Claude 10,000 veces/d√≠a:
- JSON: $1,098.19/d√≠a
- TOON: $808.01/d√≠a
- **Ahorro: $290.18/d√≠a = $106K/a√±o**

---

## üöÄ Quick Start

```python
from toonkit import encode, decode
import json

# Tu contexto (puede ser muy grande)
context = {
    "user": {...},
    "history": [...],
    "analytics": {...}
}

# Convertir a TOON (m√°s compacto)
compressed = encode(context)

# Enviar a LLM
response = client.messages.create(
    model="gpt-4",
    messages=[{"role": "user", "content": compressed}]
)

# Recuperar datos originales (si es necesario)
original = decode(compressed)
```

---

## üìä Resultados T√≠picos

| Caso de Uso | Reducci√≥n | Ahorro/Mes | ROI |
|---|---|---|---|
| Customer Support | 51.9% | $1,185 | 285% (4.2 meses) |
| Analytics | 32.4% | $217 | 52% (23 meses) |
| Document Processing | 2.4% | $29 | 7% (170 meses) |
| **CRM a escala** | **26.4%** | **$8,743** | ****475% (7 d√≠as)**\*\* |

*\*CRM con 10K llamadas/d√≠a a Claude*

---

## üéØ Cu√°ndo Usar TOONKIT

### ‚úÖ Perfecto para:
- APIs de LLM con contextos largos (OpenAI, Claude, Gemini)
- Sistemas de soporte con historial conversacional
- Pipelines de an√°lisis de datos
- Archivos de configuraci√≥n comprimidos
- Cualquier contexto enviado a modelos de IA m√∫ltiples veces

### ‚ùå No es ideal para:
- Datos sin estructura
- Objetos muy peque√±os (< 100 bytes)
- Cuando la legibilidad humana es cr√≠tica

---

## üíæ Instalaci√≥n

```bash
pip install toonkit
```

---

## üîó Referencias

- **GitHub:** https://github.com/cafep/toonkit
- **Documentaci√≥n:** [Ver PROJECT_SUMMARY.md](../PROJECT_SUMMARY.md)
- **Changelog:** [Ver CHANGELOG.md](../CHANGELOG.md)

---

## ‚ùì FAQ

**P: ¬øQu√© es TOONKIT?**
R: Es un formato de serializaci√≥n optimizado para LLMs que reduce tokens en 30-70%.

**P: ¬øEs compatible con JSON?**
R: No es JSON, pero es reversible. `encode(data)` ‚Üí comprimido ‚Üí `decode()` ‚Üí datos originales.

**P: ¬øQu√© LLMs soporta?**
R: Todos - OpenAI, Claude, Gemini, Llama, etc. Solo necesita que acepte texto.

**P: ¬øHay p√©rdida de datos?**
R: No. TOONKIT es 100% reversible. El round-trip es perfecto.

**P: ¬øCu√°nto se ahorra?**
R: 30-70% t√≠picamente. Depende de la estructura de datos. Ver ejemplos arriba.

---

Creado con ‚ù§Ô∏è para desarrolladores que quieren ahorrar dinero en APIs de IA.
