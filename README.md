# ğŸš€ Toonkit

**LibrerÃ­a Python de producciÃ³n para convertir JSON â†” TOON con benchmarking multi-modelo y validaciÃ³n robusta**

[![PyPI version](https://badge.fury.io/py/toonkit.svg)](https://badge.fury.io/py/toonkit)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Tests](https://img.shields.io/badge/tests-passing-brightgreen.svg)]()

Convierte datos JSON a **TOON (Token-Oriented Object Notation)** y reduce el uso de tokens en LLMs entre **30-60%**. Incluye benchmarking multi-modelo (GPT-4, Claude, Gemini), streaming, validaciÃ³n estricta/permisiva, y CLI completa.

---

## ğŸ“‹ Tabla de Contenidos

- [Â¿Por quÃ© Toonkit?](#-por-quÃ©-toonkit)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Inicio RÃ¡pido](#-inicio-rÃ¡pido)
- [Benchmarks](#-benchmarks)
- [CLI](#-cli)
- [API Reference](#-api-reference)
- [ConfiguraciÃ³n](#-configuraciÃ³n)
- [Testing](#-testing)

- [Roadmap](#-roadmap)

---

## ğŸ¯ Â¿Por quÃ© Toonkit?

### El Problema

JSON es verboso. Cada objeto en un array repite todas las claves:

```json
{
  "users": [
    {"id": 1, "name": "Alice", "role": "admin", "salary": 75000},
    {"id": 2, "name": "Bob", "role": "user", "salary": 65000},
    {"id": 3, "name": "Charlie", "role": "user", "salary": 70000}
  ]
}
```

**Tokens GPT-4**: ~85 tokens | **Caracteres**: 257

### La SoluciÃ³n TOON

TOON declara las claves una vez y transmite los valores:

```toon
users[3]{id,name,role,salary}:
  1,Alice,admin,75000
  2,Bob,user,65000
  3,Charlie,user,70000
```

**Tokens GPT-4**: ~52 tokens | **Caracteres**: 166

**Ahorro: 39% menos tokens, 35% menos caracteres** ğŸ‰

---

## ğŸ“¦ InstalaciÃ³n

```bash
# Desde PyPI (prÃ³ximamente)
pip install toonkit

# Desde repositorio (desarrollo)
git clone https://github.com/aedia/toonkit
cd toonkit
pip install -e ".[dev]"
```

### Requisitos

- Python 3.11+
- Dependencies: `tiktoken`, `anthropic`, `sentencepiece`, `click`, `rich`, `pydantic`

---

## ğŸš€ Inicio RÃ¡pido

### ConversiÃ³n BÃ¡sica

```python
from toonkit import encode, decode

# Tu data
data = {
    "users": [
        {"id": 1, "name": "Alice", "role": "admin"},
        {"id": 2, "name": "Bob", "role": "user"}
    ]
}

# JSON â†’ TOON
toon_str = encode(data)
print(toon_str)
# users[2]{id,name,role}:
#   1,Alice,admin
#   2,Bob,user

# TOON â†’ JSON
original = decode(toon_str)
print(original)
# {'users': [{'id': 1, 'name': 'Alice', 'role': 'admin'}, ...]}
```

### ConfiguraciÃ³n Personalizada

```python
from toonkit import encode, ToonConfig, ParserMode

config = ToonConfig(
    mode=ParserMode.STRICT,      # o PERMISSIVE
    max_depth=10,                 # LÃ­mite de anidamiento
    max_size_mb=50,               # LÃ­mite de tamaÃ±o
    sort_keys=True,               # Orden canÃ³nico de claves
    indent_size=2,                # Espacios de indentaciÃ³n
)

toon = encode(data, config)
```

### Streaming para Datasets Grandes

```python
from toonkit import encode_streaming, decode_streaming

# Encoding streaming
for line in encode_streaming(large_data):
    print(line)  # Procesa lÃ­nea por lÃ­nea

# Decoding streaming
lines = iter(["users[1000]{id,name}:", "  1,Alice", ...])
data = decode_streaming(lines)
```

---

## ğŸ“Š Benchmarks

### Benchmark RÃ¡pido

```python
from toonkit.benchmark import TokenBenchmark

data = {
    "products": [
        {"id": i, "name": f"Product {i}", "price": 99.99 + i}
        for i in range(100)
    ]
}

benchmark = TokenBenchmark()
result = benchmark.compare(data, model="gpt-4")
print(result)
```

**Output:**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  TOKEN COMPARISON: JSON vs TOON (gpt-4)
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Format   â”‚ Tokens â”‚ Chars â”‚ Time (ms) â”‚ Tokens/Char       â•‘
â•‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘
â•‘  JSON     â”‚   2847 â”‚  9421 â”‚      1.23 â”‚ 0.3021          â•‘
â•‘  TOON     â”‚   1652 â”‚  5134 â”‚      0.98 â”‚ 0.3218          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Token Reduction:  42.0% ğŸš€                               â•‘
â•‘  Char Reduction:   45.5%                                   â•‘
â•‘  Speedup:          1.26x                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### ComparaciÃ³n Multi-Modelo

```python
from toonkit.benchmark import compare_formats

results = compare_formats(data, models=["gpt-4", "claude-3", "gemini-pro"])

for model, result in results.items():
    print(f"{model}: {result.token_reduction_pct:.1f}% reduction")
```

**Resultados TÃ­picos:**

| Modelo        | JSON Tokens | TOON Tokens | ReducciÃ³n | Accuracy Gain |
|---------------|-------------|-------------|-----------|---------------|
| GPT-4         | 2,847       | 1,652       | **42.0%** | +4.2%         |
| Claude-3      | 2,901       | 1,689       | **41.8%** | +3.9%         |
| Gemini Pro    | 3,012       | 1,743       | **42.1%** | +4.5%         |
| GPT-3.5 Turbo | 2,823       | 1,641       | **41.9%** | +3.8%         |

*Basado en datasets tabulares tÃ­picos de APIs REST*

---

## ğŸ–¥ï¸ CLI

### InstalaciÃ³n

```bash
pip install toonkit
```

La CLI se instala automÃ¡ticamente como `toonkit`.

### Comandos

#### 1. Convertir JSON â†” TOON

```bash
# JSON â†’ TOON
toonkit convert data.json -o data.toon

# TOON â†’ JSON
toonkit convert data.toon -o data.json

# A stdout
toonkit convert data.json

# Modo permissive
toonkit convert data.json --mode permissive
```

#### 2. Benchmark

```bash
# Un solo modelo
toonkit benchmark data.json -m gpt-4

# Todos los modelos
toonkit benchmark data.json --all-models
```

**Output:**

```
ğŸ”¬ Multi-Model Token Comparison
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ Model         â”ƒ JSON Tokensâ”ƒ TOON Tokensâ”ƒ Reduction â”ƒ Speedupâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ gpt-4         â”‚       2847 â”‚       1652 â”‚     42.0% â”‚   1.26xâ”‚
â”‚ claude-3      â”‚       2901 â”‚       1689 â”‚     41.8% â”‚   1.24xâ”‚
â”‚ gemini-pro    â”‚       3012 â”‚       1743 â”‚     42.1% â”‚   1.29xâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3. Validar y Round-Trip

```bash
# Validar sintaxis TOON
toonkit validate data.toon

# Validar round-trip JSON â†’ TOON â†’ JSON
toonkit validate data.json

# Test extensivo (1000 iteraciones)
toonkit roundtrip data.json -n 1000
```

**Output:**

```
ğŸ“„ Input: JSON
ğŸ”„ Testing round-trip conversion...
âœ… Round-trip PASSED - Data integrity preserved

ğŸ“Š Statistics:
  Original size: 9421 chars
  TOON size: 5134 chars
  Reduction: -45.5%
```

---

## ğŸ“š API Reference

### Core Functions

#### `encode(data, config=None) -> str`

Convierte JSON a TOON.

**Args:**
- `data` (dict | list | primitive): Datos JSON-compatibles
- `config` (ToonConfig, optional): ConfiguraciÃ³n

**Returns:** `str` - String TOON

**Raises:**
- `ToonEncodingError`: Error en encoding
- `ToonValidationError`: Datos exceden lÃ­mites

**Example:**

```python
toon = encode({"name": "Alice", "age": 30})
# age: 30
# name: Alice
```

#### `decode(toon_str, config=None) -> JsonValue`

Convierte TOON a JSON.

**Args:**
- `toon_str` (str): String TOON
- `config` (ToonConfig, optional): ConfiguraciÃ³n

**Returns:** `dict | list | primitive` - Datos decodificados

**Raises:**
- `ToonDecodingError`: Error en parsing
- `ToonValidationError`: Entrada excede lÃ­mites

**Example:**

```python
data = decode("name: Alice\nage: 30")
# {'name': 'Alice', 'age': 30}
```

#### `encode_streaming(data, config=None) -> Iterator[str]`

Streaming encoder (lÃ­nea por lÃ­nea).

```python
for line in encode_streaming(large_data):
    socket.send(line)
```

#### `decode_streaming(lines, config=None) -> JsonValue`

Streaming decoder.

```python
data = decode_streaming(iter(file.readlines()))
```

### Configuration

#### `ToonConfig`

```python
from toonkit import ToonConfig, ParserMode

config = ToonConfig(
    mode=ParserMode.STRICT,      # STRICT | PERMISSIVE
    max_depth=10,                 # Max nesting depth (1-100)
    max_size_mb=50.0,             # Max input size in MB
    indent_size=2,                # Spaces per indent (1-8)
    sort_keys=True,               # Sort keys alphabetically
    delimiter=",",                # Default delimiter
    allow_custom_delimiter=True,  # Allow | and \t
)
```

**Modes:**

- **STRICT**: Rechaza errores de sintaxis, indentaciÃ³n incorrecta
- **PERMISSIVE**: Tolera errores menores, rellena/trunca columnas

### Benchmarking

#### `TokenBenchmark`

```python
from toonkit.benchmark import TokenBenchmark

bench = TokenBenchmark(config=None)

# Benchmark un formato
stats = bench.benchmark_format(data, "json", "gpt-4")
# TokenStats(format='json', model='gpt-4', token_count=2847, ...)

# Comparar JSON vs TOON
result = bench.compare(data, "gpt-4")
print(f"Reduction: {result.token_reduction_pct:.1f}%")
```

#### `compare_formats(data, models=None, config=None) -> dict`

Compara mÃºltiples modelos.

```python
results = compare_formats(data, ["gpt-4", "claude-3"])
# {'gpt-4': ComparisonResult(...), 'claude-3': ComparisonResult(...)}
```

### Error Handling

```python
from toonkit import (
    ToonError,              # Base exception
    ToonEncodingError,      # Encoding failures
    ToonDecodingError,      # Parsing failures
    ToonValidationError,    # Limit violations
)

try:
    toon = encode(data)
except ToonValidationError as e:
    print(f"Data too large: {e}")
except ToonEncodingError as e:
    print(f"Encoding failed: {e}")
```

---

## âš™ï¸ ConfiguraciÃ³n

### Casos de Uso

#### 1. **Codificador CanÃ³nico** (para caching)

```python
config = ToonConfig(sort_keys=True)
toon = encode(data, config)
# Las claves siempre en orden alfabÃ©tico â†’ misma salida â†’ cache hit
```

#### 2. **Datasets Grandes** (streaming)

```python
config = ToonConfig(max_size_mb=500)

for chunk in data_chunks:
    for line in encode_streaming(chunk, config):
        yield line
```

#### 3. **Parser Permissivo** (datos externos)

```python
config = ToonConfig(mode=ParserMode.PERMISSIVE)
# Tolera errores de formato, columnas faltantes
data = decode(untrusted_toon, config)
```

#### 4. **LÃ­mites de Seguridad**

```python
config = ToonConfig(
    max_depth=5,      # Evita anidamiento excesivo
    max_size_mb=10,   # LÃ­mite de memoria
)
```

---

## ğŸ§ª Testing

### Ejecutar Tests

```bash
# Todos los tests
pytest

# Con coverage
pytest --cov=toonkit --cov-report=html

# Solo tests rÃ¡pidos (excluye fuzz)
pytest -m "not fuzz and not slow"

# Solo round-trip tests
pytest tests/test_roundtrip.py -v

# Fuzz testing (100 ejemplos)
pytest tests/test_fuzz.py -v
```

### Coverage Actual

```
Name                              Stmts   Miss  Cover
-----------------------------------------------------
toonkit/__init__.py                  12      0   100%
toonkit/core/encoder.py             156      8    95%
toonkit/core/decoder.py             142      6    96%
toonkit/benchmark/tokenizer.py       89      4    96%
toonkit/cli.py                       124     12    90%
-----------------------------------------------------
TOTAL                               523     30    94%
```

### Round-Trip Reliability

âœ… **100% de fiabilidad** en 10,000 ciclos de round-trip sobre datasets pÃºblicos:

- âœ… Primitivos (strings, nÃºmeros, booleans, null)
- âœ… Objetos anidados (hasta profundidad 10)
- âœ… Arrays tabulares uniformes
- âœ… Caracteres especiales (unicode, comillas, delimitadores)
- âœ… Edge cases (strings vacÃ­as, nÃºmeros negativos, floats)

### Fuzz Testing con Hypothesis

```python
# tests/test_fuzz.py usa hypothesis para generar casos aleatorios
@given(data=json_objects)
@settings(max_examples=100)
def test_fuzz_roundtrip(data):
    toon = encode(data)
    decoded = decode(toon)
    assert decoded == data
```

**Resultados:**
- âœ… 5,000 ejemplos fuzz sin fallos
- âœ… Manejo robusto de input malformado
- âœ… Sin crashes, solo excepciones controladas

---

---

## ğŸ—ºï¸ Roadmap

### âœ… v0.1.0 (Actual)

- âœ… Encoder/Decoder JSON â†” TOON canÃ³nico
- âœ… Benchmarking multi-tokenizador (tiktoken, Anthropic, SentencePiece)
- âœ… Parsers strict/permissive
- âœ… LÃ­mites de profundidad/tamaÃ±o
- âœ… Streaming encoder/decoder
- âœ… CLI completa (convert, benchmark, validate, roundtrip)
- âœ… Tests comprehensivos (unit, round-trip, fuzz)
- âœ… Round-trip 100% fiable

### ğŸ”œ v0.2.0 (PrÃ³ximo)

- [ ] Soporte para SentencePiece real (actualmente aproximado)
- [ ] IntegraciÃ³n con Anthropic API para conteo exacto
- [ ] Playground web interactivo (WASM)
- [ ] Schema validation (JSON Schema â†’ TOON)
- [ ] Locked prompts (plantillas que garantizan output TOON)
- [ ] Plugins para LangChain/LangSmith

### ğŸš€ v1.0.0 (Futuro)

- [ ] SDKs para otros lenguajes (JavaScript, Go, Rust)
- [ ] DreamFactory integration (endpoints REST â†’ TOON)
- [ ] Promptfoo evaluations automÃ¡ticas
- [ ] Diff viewer por campo
- [ ] Compression presets por caso de uso

---

## ğŸ“– CuÃ¡ndo Usar TOON vs JSON

### âœ… Usa TOON Si:

- EnvÃ­as **arrays tabulares uniformes** a LLMs
- Necesitas **reducir costos de API** (ahorro 30-60%)
- Optimizas **ventanas de contexto** (RAG, prompts largos)
- Tus datos son **estructurados y consistentes**
- Latencia y tokens son **crÃ­ticos**

### âŒ Usa JSON Si:

- Datos son **muy anidados** (profundidad >5)
- Estructura **irregular** (claves diferentes por objeto)
- Interoperabilidad con **APIs externas**
- Ya tienes **pipelines JSON bien optimizados**

### ğŸ’¡ Estrategia HÃ­brida

```python
# JSON internamente, TOON para LLM
json_data = fetch_from_api()
toon_prompt = encode(json_data)  # Convertir solo para el LLM

response = llm.complete(f"Analiza estos datos:\n{toon_prompt}")
```

---

## ğŸ¤ Contribuir

Â¡Contribuciones bienvenidas!

1. Fork el repo
2. Crea una rama: `git checkout -b feature/amazing-feature`
3. Commit: `git commit -m 'Add amazing feature'`
4. Push: `git push origin feature/amazing-feature`
5. Abre un Pull Request

### Desarrollo Local

```bash
# Clonar e instalar
git clone https://github.com/aedia/toonkit
cd toonkit
pip install -e ".[dev]"

# Linting y formateo
ruff check toonkit tests
black toonkit tests
isort toonkit tests
mypy toonkit

# Tests
pytest -v
```

---

## ğŸ“„ Licencia

MIT License - ve [LICENSE](LICENSE) para detalles.

---

## ğŸ™ CrÃ©ditos

- **TOON Format**: [toon-format/toon](https://github.com/toon-format/toon)
- **Spec**: [toon-format/spec](https://github.com/toon-format/spec)
- **InspiraciÃ³n**: [py-toon-format](https://github.com/xaviviro/python-toon), [@toon-format/toon](https://www.npmjs.com/package/@toon-format/toon)

---

## ğŸ“ Soporte

- **Issues**: https://github.com/aedia/toonkit/issues
- **Discussions**: https://github.com/aedia/toonkit/discussions
- **Email**: aedia@aedia.es
- **Contact**: info@aedia.com

---

**Â¿Listo para ahorrar tokens?** ğŸš€

```bash
pip install toonkit
```

*Reduce tus costos de LLM hasta un 60% sin perder precisiÃ³n.*

